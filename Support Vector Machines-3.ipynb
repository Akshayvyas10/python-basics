{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "'''Q1. In order to predict house price based on several characteristics, such as location, square footage,\nnumber of bedrooms, etc., you are developing an SVM regression model. Which regression metric in this\nsituation would be the best to employ?\nDATASET LINK : https://drive.google.com/file/d/1Z9oLpmt6IDRNw7IeNcHYTGeJRYypRSC0/view?usp=share_link'''",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "'''UNABLE TO DO IT'''",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#Q2. You have built an SVM regression model and are trying to decide between using MSE or R-squared as\nyour evaluation metric. Which metric would be more appropriate if your goal is to predict the actual price\nof a house as accurately as possible?",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "'''\nIn the context of house price prediction, Mean Squared Error (MSE) would be the more appropriate evaluation metric\nif your goal is to predict the actual price of a house as accurately as possible.\n\nHere's why:\n\nFocus on absolute differences:MSE directly measures the average squared difference between predicted and actual prices. \n                              This makes it ideal for scenarios where accurate predictions are crucial, as it penalizes larger errors more heavily.   \nInterpretability: MSE is easily interpretable. A lower MSE indicates that the model's predictions are closer to the true values on average.   \nCommonly used: MSE is a widely used metric in regression problems, making it a familiar and reliable choice.   \n\nWhile R-squared can also be useful, it has some limitations:\nInterpretability: R-squared measures the proportion of variance explained by the model, which can be less intuitive than MSE.   \nSensitivity to outliers: R-squared can be sensitive to outliers, as they can significantly impact the variance explained.   \nTherefore, for house price prediction, where accurate predictions are essential, MSE is generally a more suitable evaluation metric.'''",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#Q3. You have a dataset with a significant number of outliers and are trying to select an appropriate\nregression metric to use with your SVM model. Which metric would be the most appropriate in this\nscenario?",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "'''\nMean Absolute Error (MAE) is generally the most appropriate regression metric to use with your SVM model when dealing with a dataset containing a significant number of outliers.\n\nHere's why:\n\nRobustness to Outliers: MAE is less sensitive to outliers compared to Mean Squared Error (MSE). \n                        This is because it calculates the absolute difference between predicted and actual values, which means that large errors don't have as much impact on the overall metric.\nInterpretability: MAE is easily interpretable. A lower MAE indicates that the model's predictions are closer to the true values on average in absolute terms.\n\nWhy MAE is preferable over MSE in this case:\n\nMSE is heavily influenced by outliers: Large errors squared in MSE can significantly inflate the overall metric, making it less representative of the model's performance on the majority of data points.\nMAE provides a more robust measure: MAE focuses on the average absolute difference, which is less affected by outliers.\n\nAdditional considerations:\n\nDomain knowledge: The specific consequences of outliers in your application may influence your choice of metric.\nData distribution: If outliers are particularly extreme, you might consider using a more robust loss function within your SVM model.'''",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#Q4. You have built an SVM regression model using a polynomial kernel and are trying to select the best\nmetric to evaluate its performance. You have calculated both MSE and RMSE and found that both values\nare very close. Which metric should you choose to use in this case?",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "'''\nIn this case, where both MSE (Mean Squared Error) and RMSE (Root Mean Squared Error) are very close for your SVM regression model using a polynomial kernel, either metric can be used effectively.\n\nHere's a breakdown of why:\n\nMSE and RMSE are closely related: RMSE is simply the square root of MSE. This means that they will often provide similar results, especially when the errors are relatively small.\nInterpretability: Both metrics are easily interpretable. MSE measures the average squared error, while RMSE measures the average error in the same units as the target variable.\nDomain knowledge: Consider the specific context of your problem and the relative importance of minimizing large errors versus minimizing the average error.\n\nWhile both metrics are valid, here are some considerations:\n\nMSE: If you want to emphasize large errors, MSE might be more suitable.\nRMSE: If you prefer to interpret the error in the same units as the target variable, RMSE might be more intuitive.\nUltimately, the choice between MSE and RMSE depends on your specific preferences and the goals of your analysis.\nIn many cases, the difference between the two metrics will be minimal, so either can be used effectively.\n\nAdditional tips:\n\nVisualize the errors: Plot the errors against the predicted values to identify any patterns or outliers.\nConsider other metrics: If you have specific concerns about the distribution of errors, you might explore other metrics like Mean Absolute Error (MAE) or Huber Loss.'''",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#Q5. You are comparing the performance of different SVM regression models using different kernels (linear,\npolynomial, and RBF) and are trying to select the best evaluation metric. Which metric would be most\nappropriate if your goal is to measure how well the model explains the variance in the target variable?",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "'''\nR-squared (R²) is the most appropriate metric to use when comparing the performance of different SVM regression models using various kernels (linear, polynomial, and RBF) with the goal of measuring how well the model explains the variance in the target variable.\n\nHere's why:\n\nExplanation of Variance:\n\nR² measures the proportion of the variance in the target variable that is explained by the model. A higher R² value indicates that the model is better at explaining the variation in the target variable.   \nComparison of Models: R² is a good metric for comparing the performance of different models, especially when the goal is to understand how much of the variability in the target variable is captured by the model.\nIntuitive Interpretation: R² is relatively easy to interpret, as it ranges from 0 to 1. A value of 1 indicates that the model explains 100% of the variance in the target variable, while a value of 0 indicates that the model explains none of the variance.   \nWhile other metrics like Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) can also be used to evaluate regression models, R² is particularly useful when comparing the performance of different models in terms of their ability to explain the variance in the target variable.'''\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}